{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1"
      ],
      "metadata": {
        "id": "upRwXUSdM6Lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh4OEGWkMlb_",
        "outputId": "7de3f7a7-2a23-4435-8430-2121c4af0e1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.23.3)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.5.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (3.8.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OKmP_a0bMiT3",
        "outputId": "3d66a8fa-9d80-48cb-9f65-dc9a7d7703c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "    support               itemsets\n",
            "0      1.00                (bread)\n",
            "1      0.75               (butter)\n",
            "2      0.75                  (jam)\n",
            "3      0.75                 (milk)\n",
            "4      0.75        (butter, bread)\n",
            "5      0.75           (jam, bread)\n",
            "6      0.75          (milk, bread)\n",
            "7      0.50          (butter, jam)\n",
            "8      0.50         (butter, milk)\n",
            "9      0.50            (milk, jam)\n",
            "10     0.50   (butter, jam, bread)\n",
            "11     0.50  (butter, milk, bread)\n",
            "12     0.50     (milk, jam, bread)\n",
            "\n",
            "Association Rules:\n",
            "       antecedents     consequents  antecedent support  consequent support  \\\n",
            "0         (butter)         (bread)                0.75                1.00   \n",
            "1          (bread)        (butter)                1.00                0.75   \n",
            "2            (jam)         (bread)                0.75                1.00   \n",
            "3          (bread)           (jam)                1.00                0.75   \n",
            "4           (milk)         (bread)                0.75                1.00   \n",
            "5          (bread)          (milk)                1.00                0.75   \n",
            "6    (butter, jam)         (bread)                0.50                1.00   \n",
            "7          (bread)   (butter, jam)                1.00                0.50   \n",
            "8   (butter, milk)         (bread)                0.50                1.00   \n",
            "9          (bread)  (butter, milk)                1.00                0.50   \n",
            "10     (milk, jam)         (bread)                0.50                1.00   \n",
            "11         (bread)     (milk, jam)                1.00                0.50   \n",
            "\n",
            "    support  confidence  lift  representativity  leverage  conviction  \\\n",
            "0      0.75        1.00   1.0               1.0       0.0         inf   \n",
            "1      0.75        0.75   1.0               1.0       0.0         1.0   \n",
            "2      0.75        1.00   1.0               1.0       0.0         inf   \n",
            "3      0.75        0.75   1.0               1.0       0.0         1.0   \n",
            "4      0.75        1.00   1.0               1.0       0.0         inf   \n",
            "5      0.75        0.75   1.0               1.0       0.0         1.0   \n",
            "6      0.50        1.00   1.0               1.0       0.0         inf   \n",
            "7      0.50        0.50   1.0               1.0       0.0         1.0   \n",
            "8      0.50        1.00   1.0               1.0       0.0         inf   \n",
            "9      0.50        0.50   1.0               1.0       0.0         1.0   \n",
            "10     0.50        1.00   1.0               1.0       0.0         inf   \n",
            "11     0.50        0.50   1.0               1.0       0.0         1.0   \n",
            "\n",
            "    zhangs_metric  jaccard  certainty  kulczynski  \n",
            "0             0.0     0.75        0.0       0.875  \n",
            "1             0.0     0.75        0.0       0.875  \n",
            "2             0.0     0.75        0.0       0.875  \n",
            "3             0.0     0.75        0.0       0.875  \n",
            "4             0.0     0.75        0.0       0.875  \n",
            "5             0.0     0.75        0.0       0.875  \n",
            "6             0.0     0.50        0.0       0.750  \n",
            "7             0.0     0.50        0.0       0.750  \n",
            "8             0.0     0.50        0.0       0.750  \n",
            "9             0.0     0.50        0.0       0.750  \n",
            "10            0.0     0.50        0.0       0.750  \n",
            "11            0.0     0.50        0.0       0.750  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/association_rules.py:182: RuntimeWarning: invalid value encountered in divide\n",
            "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "dataset = [\n",
        "    ['milk', 'bread', 'butter'],\n",
        "    ['bread', 'butter', 'jam'],\n",
        "    ['milk', 'bread', 'jam'],\n",
        "    ['milk', 'bread', 'butter', 'jam']\n",
        "]\n",
        "\n",
        "# Convert transactions into a one-hot encoded DataFrame\n",
        "te = TransactionEncoder()\n",
        "te_data = te.fit_transform(dataset)\n",
        "df = pd.DataFrame(te_data, columns=te.columns_)\n",
        "\n",
        "# Apply Apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
        "\n",
        "# Add the 'num_itemsets' parameter for older versions of mlxtend\n",
        "rules = association_rules(\n",
        "    frequent_itemsets, metric=\"lift\", min_threshold=1.0, num_itemsets=len(frequent_itemsets)\n",
        ")\n",
        "\n",
        "# Display the results\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2"
      ],
      "metadata": {
        "id": "J-ewcl-cNOYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pandas as pd\n",
        "\n",
        "# Sample one-hot encoded dataset\n",
        "data = {\n",
        "    'milk': [1, 0, 1, 1, 0],\n",
        "    'bread': [1, 1, 1, 0, 1],\n",
        "    'butter': [0, 1, 0, 1, 1],\n",
        "    'eggs': [1, 0, 1, 1, 0],\n",
        "    'cheese': [0, 1, 1, 0, 1]\n",
        "}\n",
        "\n",
        "# Convert the data to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Generate frequent itemsets\n",
        "min_support = 0.6  # Minimum support threshold\n",
        "frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7, num_itemsets=len(frequent_itemsets))\n",
        "\n",
        "# Display results\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABLGpMPMNQRO",
        "outputId": "23587881-e7e2-43f6-bee5-f39eec9f3b1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "   support         itemsets\n",
            "0      0.6           (milk)\n",
            "1      0.8          (bread)\n",
            "2      0.6         (butter)\n",
            "3      0.6           (eggs)\n",
            "4      0.6         (cheese)\n",
            "5      0.6     (milk, eggs)\n",
            "6      0.6  (cheese, bread)\n",
            "\n",
            "Association Rules:\n",
            "  antecedents consequents  antecedent support  consequent support  support  \\\n",
            "0      (milk)      (eggs)                 0.6                 0.6      0.6   \n",
            "1      (eggs)      (milk)                 0.6                 0.6      0.6   \n",
            "2    (cheese)     (bread)                 0.6                 0.8      0.6   \n",
            "3     (bread)    (cheese)                 0.8                 0.6      0.6   \n",
            "\n",
            "   confidence      lift  representativity  leverage  conviction  \\\n",
            "0        1.00  1.666667               1.0      0.24         inf   \n",
            "1        1.00  1.666667               1.0      0.24         inf   \n",
            "2        1.00  1.250000               1.0      0.12         inf   \n",
            "3        0.75  1.250000               1.0      0.12         1.6   \n",
            "\n",
            "   zhangs_metric  jaccard  certainty  kulczynski  \n",
            "0            1.0     1.00      1.000       1.000  \n",
            "1            1.0     1.00      1.000       1.000  \n",
            "2            0.5     0.75      1.000       0.875  \n",
            "3            1.0     0.75      0.375       0.875  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3"
      ],
      "metadata": {
        "id": "K4qN7iXDNr7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "\n",
        "# Transaction data as a list of lists\n",
        "transactions = [\n",
        "    ['1', '3', '4'],\n",
        "    ['2', '3', '5'],\n",
        "    ['1', '2', '3', '5'],\n",
        "    ['2', '5']\n",
        "]\n",
        "\n",
        "\n",
        "# Function to get unique items from transactions\n",
        "def get_unique_items(transactions):\n",
        "    items = set()\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            items.add(item)\n",
        "    return items\n",
        "\n",
        "\n",
        "items = get_unique_items(transactions)\n",
        "print(items)\n"
      ],
      "metadata": {
        "id": "sCr0W1KoNtEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Candidate Itemsets\n",
        "def generate_candidates(itemset, length):\n",
        "    return list(combinations(itemset, length))\n",
        "\n",
        "\n",
        "h = generate_candidates(items, 2)\n",
        "print(h)\n"
      ],
      "metadata": {
        "id": "4SQ_zH0uN2Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Support for Itemsets\n",
        "# Function to calculate the support of an itemset\n",
        "def calculate_support(transactions, itemsets):\n",
        "    support_count = {}\n",
        "    for itemset in itemsets:\n",
        "        support_count[itemset] = 0\n",
        "        for transaction in transactions:\n",
        "            if set(itemset).issubset(set(transaction)):\n",
        "                support_count[itemset] += 1\n",
        "    return support_count\n",
        "\n",
        "\n",
        "# Define minimum support threshold (e.g., 2 occurrences)\n",
        "min_support = 2\n",
        "\n",
        "# Prune Itemsets Based on Minimum Support\n",
        "def prune_itemsets(support_count, min_support):\n",
        "    frequent_itemsets = []\n",
        "    for itemset, count in support_count.items():\n",
        "        if count >= min_support:\n",
        "            frequent_itemsets.append(itemset)\n",
        "    return frequent_itemsets\n",
        "\n",
        "# Implement the Apriori Algorithm\n",
        "def apriori(transactions, min_support):\n",
        "    # Step 1: Get unique items from the transactions\n",
        "    items = get_unique_items(transactions)\n",
        "\n",
        "\n",
        "    # Step 2: Initialize variables\n",
        "    length = 1\n",
        "    frequent_itemsets = []\n",
        "\n",
        "\n",
        "    prev_freq_itemset = None\n",
        "    # Step 3: Generate candidate itemsets of increasing lengths\n",
        "    while True:\n",
        "        if length == 1:\n",
        "            candidates = generate_candidates(items, length)\n",
        "        else:\n",
        "            candidates = generate_candidates(set.union(*[set(item) for item in frequent_itemsets]), length)\n",
        "\n",
        "\n",
        "        # Step 4: Calculate the support of candidate itemsets\n",
        "        support_count = calculate_support(transactions, candidates)\n",
        "\n",
        "\n",
        "        # Step 5: Prune itemsets that do not meet min support\n",
        "        frequent_itemsets = prune_itemsets(support_count, min_support)\n",
        "\n",
        "\n",
        "        # If no frequent itemsets found, stop\n",
        "        if not frequent_itemsets:\n",
        "            return prev_freq_itemset\n",
        "        prev_freq_itemset = frequent_itemsets\n",
        "        # Print frequent itemsets for this round\n",
        "        print(f\"Frequent {length}-itemsets:\", frequent_itemsets)\n",
        "\n",
        "\n",
        "        # Move to the next length\n",
        "        length += 1\n",
        "    return frequent_itemsets\n",
        "\n",
        "\n",
        "# Run the Apriori algorithm on our transaction dataset\n",
        "freq_itemset = apriori(transactions, min_support)\n"
      ],
      "metadata": {
        "id": "wY82BuVDN6tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Association Rules\n",
        "# Function to generate association rules from frequent itemsets\n",
        "def generate_association_rules(frequent_itemsets, transactions, min_confidence=0.7):\n",
        "    rules = []\n",
        "    for itemset in frequent_itemsets:\n",
        "        if len(itemset) > 1:\n",
        "            for i in range(1, len(itemset)):\n",
        "                antecedents = list(combinations(itemset, i))\n",
        "                for antecedent in antecedents:\n",
        "                    consequent = tuple(set(itemset) - set(antecedent))\n",
        "                    antecedent_support = sum([1 for t in transactions if set(antecedent).issubset(set(t))])\n",
        "                    itemset_support = sum([1 for t in transactions if set(itemset).issubset(set(t))])\n",
        "                    confidence = itemset_support / antecedent_support if antecedent_support != 0 else 0\n",
        "                    if confidence >= min_confidence:\n",
        "                        rules.append((antecedent, consequent, confidence))\n",
        "    return rules\n",
        "\n",
        "\n",
        "# Generate rules with min confidence threshold\n",
        "rules = generate_association_rules(apriori(transactions, min_support), transactions, min_confidence=0.7)\n",
        "for rule in rules:\n",
        "    print(f\"Rule: {rule[0]} -> {rule[1]} (confidence: {rule[2]:.2f})\")\n"
      ],
      "metadata": {
        "id": "TukJRw-WOCRv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}